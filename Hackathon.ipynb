{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NEERAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NEERAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords, common words such as  \"a,\" \"the,\" \"it,\" etc.\n",
    "stop_words = stopwords.words('english')\n",
    "    \n",
    "#Initialize stemmer, which will take words and convert words to their \"stem,\" e.g. Playing-> Play\n",
    "ps = PorterStemmer() \n",
    "\n",
    "# Removes non-alphabetical characters, whitespaces, and converts all letters to lowercase\n",
    "def clean_text(txt): \n",
    "    txt= txt.lower()   #lowercase\n",
    "    txt= re.sub(\"[^a-zA-Z]\",\" \",txt) #Remove everything except alphabetical characters \n",
    "    txt= word_tokenize(txt) #tokenize (split into list and remove whitespace)\n",
    "    \n",
    "    #initialize list to store clean text\n",
    "    clean_text=\"\"\n",
    "    \n",
    "    #iterate over each word\n",
    "    for w in txt:      \n",
    "        #remove stopwords\n",
    "        if w not in stop_words:\n",
    "            #stem=ps.stem(w) #stem \n",
    "            stem=w\n",
    "            clean_text = clean_text + stem +\" \" \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "train['TITLE']=train['TITLE'].apply(clean_text)\n",
    "train['ABSTRACT']=train['ABSTRACT'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>reconstructing subject specific effect maps</td>\n",
       "      <td>predictive models allow subject specific infer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>rotation invariance neural network</td>\n",
       "      <td>rotation invariance translation invariance gre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>spherical polyharmonics poisson kernels polyha...</td>\n",
       "      <td>introduce develop notion spherical polyharmoni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>finite element approximation stochastic maxwel...</td>\n",
       "      <td>stochastic landau lifshitz gilbert llg equatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>comparative study discrete wavelet transforms ...</td>\n",
       "      <td>fourier transform infra red ftir spectra sampl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1       reconstructing subject specific effect maps    \n",
       "1   2                rotation invariance neural network    \n",
       "2   3  spherical polyharmonics poisson kernels polyha...   \n",
       "3   4  finite element approximation stochastic maxwel...   \n",
       "4   5  comparative study discrete wavelet transforms ...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0  predictive models allow subject specific infer...                 1   \n",
       "1  rotation invariance translation invariance gre...                 1   \n",
       "2  introduce develop notion spherical polyharmoni...                 0   \n",
       "3  stochastic landau lifshitz gilbert llg equatio...                 0   \n",
       "4  fourier transform infra red ftir spectra sampl...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "binary_labels=train[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "categories = list(binary_labels.columns.values)\n",
    "ax= sns.barplot(binary_labels.sum().values, categories)\n",
    "\n",
    "plt.title(\"Article\", fontsize=24)\n",
    "plt.ylabel('Article Belongs To', fontsize=18)\n",
    "plt.xlabel('Number of articles', fontsize=18)\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = binary_labels.sum().values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into training and validation set\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "xtrain, xval, ytrain, yval = train_test_split(train['ABSTRACT'], binary_labels, test_size=0.2, random_state=9)\n",
    "\n",
    "# create TF-IDF features\n",
    "# TF-IDF = Term frequency - inverse document frequency\n",
    "# Used to predict how important a word is for a document\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for Logistic Regression train:  0.718364427490016\n",
      "Accuracy score for Logistic Regression validation: 0.6417163289630512\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8750166970924795\n",
      "f1-Score validation:  0.821957385337667\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.81      0.90      0.85      1704\n",
      "             Physics       0.89      0.87      0.88      1211\n",
      "         Mathematics       0.76      0.87      0.82      1089\n",
      "          Statistics       0.72      0.85      0.78      1069\n",
      "Quantitative Biology       0.38      0.64      0.48       116\n",
      "Quantitative Finance       0.54      0.82      0.65        44\n",
      "\n",
      "           micro avg       0.78      0.87      0.82      5233\n",
      "           macro avg       0.68      0.82      0.74      5233\n",
      "        weighted avg       0.79      0.87      0.83      5233\n",
      "         samples avg       0.82      0.90      0.84      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report\n",
    "\n",
    "#Run Logistic Regrssion\n",
    "logreg = LogisticRegression(class_weight='balanced',n_jobs=-1,random_state=9)\n",
    "logreg_classifier = OneVsRestClassifier(logreg)\n",
    "\n",
    "# fit model on train data\n",
    "logreg_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=logreg_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = logreg_classifier.predict(xval_tfidf)\n",
    "\n",
    "# evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print()\n",
    "print(\"Accuracy score for Logistic Regression train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for Logistic Regression validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for Logistic Regression train:  0.6141145616021935\n",
      "Accuracy score for Logistic Regression validation: 0.60119189511323\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8153880168030069\n",
      "f1-Score validation:  0.8018851147074515\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.78      0.89      0.83      1704\n",
      "             Physics       0.90      0.84      0.87      1211\n",
      "         Mathematics       0.76      0.87      0.81      1089\n",
      "          Statistics       0.68      0.85      0.76      1069\n",
      "Quantitative Biology       0.29      0.72      0.41       116\n",
      "Quantitative Finance       0.51      0.82      0.63        44\n",
      "\n",
      "           micro avg       0.75      0.86      0.80      5233\n",
      "           macro avg       0.65      0.83      0.72      5233\n",
      "        weighted avg       0.77      0.86      0.81      5233\n",
      "         samples avg       0.80      0.89      0.82      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report\n",
    "\n",
    "#Run Logistic Regrssion\n",
    "logreg1 = LogisticRegression(class_weight='balanced',n_jobs=-1,random_state=9,C=0.07)\n",
    "logreg1_classifier = OneVsRestClassifier(logreg1)\n",
    "\n",
    "# fit model on train data\n",
    "logreg1_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=logreg1_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = logreg1_classifier.predict(xval_tfidf)\n",
    "\n",
    "# evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print()\n",
    "print(\"Accuracy score for Logistic Regression train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for Logistic Regression validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    " \n",
    "logreg1 = LogisticRegression(class_weight='balanced',n_jobs=-1,random_state=9,C=0.07)\n",
    "logreg1_classifier = OneVsRestClassifier(logreg1)\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "score=cross_val_score(logreg1_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79928476, 0.80212249, 0.80363073, 0.80286097, 0.79304193,\n",
       "       0.78756937, 0.77809545, 0.80322004, 0.80408254, 0.79820022])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.80 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Gussian NB train:  0.6609048101567623\n",
      "Accuracy score for Gussian NB validation: 0.634564958283671\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8210241676525266\n",
      "f1-Score validation:  0.8028813394334664\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.77      0.89      0.83      1704\n",
      "             Physics       0.95      0.79      0.86      1211\n",
      "         Mathematics       0.84      0.78      0.81      1089\n",
      "          Statistics       0.75      0.76      0.75      1069\n",
      "Quantitative Biology       0.67      0.02      0.03       116\n",
      "Quantitative Finance       0.00      0.00      0.00        44\n",
      "\n",
      "           micro avg       0.82      0.79      0.80      5233\n",
      "           macro avg       0.66      0.54      0.55      5233\n",
      "        weighted avg       0.82      0.79      0.79      5233\n",
      "         samples avg       0.81      0.82      0.79      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Multinomial Naive Bayes \n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = OneVsRestClassifier(MultinomialNB())\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, ytrain)\n",
    "# predict\n",
    "ytrain_pred=classifier.predict(xtrain_tfidf)\n",
    "yval_pred = classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for Gussian NB train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for Gussian NB validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(MultinomialNB())\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79539892, 0.79484686, 0.80674322, 0.81271228, 0.79873909,\n",
       "       0.7861605 , 0.78578384, 0.80774818, 0.80494905, 0.80265748])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.80 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Gussian NB train:  0.7593133456517852\n",
      "Accuracy score for Gussian NB validation: 0.6707985697258642\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8800039294660836\n",
      "f1-Score validation:  0.8200378448361717\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.82      0.88      0.85      1704\n",
      "             Physics       0.95      0.81      0.88      1211\n",
      "         Mathematics       0.88      0.78      0.83      1089\n",
      "          Statistics       0.81      0.72      0.76      1069\n",
      "Quantitative Biology       0.55      0.10      0.17       116\n",
      "Quantitative Finance       0.72      0.30      0.42        44\n",
      "\n",
      "           micro avg       0.86      0.79      0.82      5233\n",
      "           macro avg       0.79      0.60      0.65      5233\n",
      "        weighted avg       0.85      0.79      0.81      5233\n",
      "         samples avg       0.83      0.82      0.81      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=9)\n",
    "\n",
    "\n",
    "#Run SGDClassifier\n",
    "sgd_classifier = OneVsRestClassifier(sgd)\n",
    "\n",
    "# fit model on train data\n",
    "sgd_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=sgd_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = sgd_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for Gussian NB train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for Gussian NB validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.6367050128151636\n",
      "Accuracy score for SGDClassifier validation: 0.6169249106078665\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8282823810683373\n",
      "f1-Score validation:  0.8103617686467173\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.78      0.91      0.84      1704\n",
      "             Physics       0.92      0.83      0.87      1211\n",
      "         Mathematics       0.77      0.87      0.82      1089\n",
      "          Statistics       0.69      0.87      0.77      1069\n",
      "Quantitative Biology       0.33      0.72      0.45       116\n",
      "Quantitative Finance       0.48      0.82      0.61        44\n",
      "\n",
      "           micro avg       0.76      0.87      0.81      5233\n",
      "           macro avg       0.66      0.83      0.72      5233\n",
      "        weighted avg       0.78      0.87      0.82      5233\n",
      "         samples avg       0.81      0.89      0.82      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd1 = SGDClassifier(random_state=9,class_weight='balanced',n_jobs=-1,alpha=0.0010)\n",
    "\n",
    "\n",
    "#Run SGDClassifier\n",
    "sgd1_classifier = OneVsRestClassifier(sgd1)\n",
    "\n",
    "# fit model on train data\n",
    "sgd1_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=sgd1_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = sgd1_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81012091 0.80823738 0.81124143 0.81438463 0.80375084 0.79564638\n",
      " 0.79117971 0.80846325 0.81745325 0.80802163]\n",
      "\n",
      "\n",
      "f1_score: 0.81 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "sgd1_classifier = OneVsRestClassifier(sgd1)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(sgd1_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.6913035703641891\n",
      "Accuracy score for SGDClassifier validation: 0.5880810488676996\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8278073810933492\n",
      "f1-Score validation:  0.7474048442906575\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.76      0.80      0.78      1704\n",
      "             Physics       0.90      0.73      0.81      1211\n",
      "         Mathematics       0.75      0.71      0.73      1089\n",
      "          Statistics       0.73      0.66      0.69      1069\n",
      "Quantitative Biology       0.46      0.23      0.31       116\n",
      "Quantitative Finance       0.70      0.48      0.57        44\n",
      "\n",
      "           micro avg       0.77      0.72      0.75      5233\n",
      "           macro avg       0.72      0.60      0.65      5233\n",
      "        weighted avg       0.77      0.72      0.75      5233\n",
      "         samples avg       0.76      0.75      0.74      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "knnClf = KNeighborsClassifier()\n",
    "knn_classifier = OneVsRestClassifier(knnClf)\n",
    "# fit model on train data\n",
    "knn_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=knn_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = knn_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75536695 0.74881988 0.76523031 0.76176325 0.75548902 0.74648235\n",
      " 0.74041079 0.7541553  0.75987246 0.74949799]\n",
      "\n",
      "\n",
      "f1_score: 0.75 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = OneVsRestClassifier(knnClf)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(knn_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  1.0\n",
      "Accuracy score for SGDClassifier validation: 0.4154946364719905\n",
      "\n",
      "\n",
      "f1-Score Train:  1.0\n",
      "f1-Score validation:  0.6648321408915795\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.67      0.73      0.69      1704\n",
      "             Physics       0.73      0.74      0.74      1211\n",
      "         Mathematics       0.64      0.70      0.67      1089\n",
      "          Statistics       0.60      0.63      0.61      1069\n",
      "Quantitative Biology       0.21      0.34      0.26       116\n",
      "Quantitative Finance       0.23      0.50      0.32        44\n",
      "\n",
      "           micro avg       0.64      0.69      0.66      5233\n",
      "           macro avg       0.51      0.60      0.55      5233\n",
      "        weighted avg       0.65      0.69      0.67      5233\n",
      "         samples avg       0.63      0.72      0.65      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier(random_state=9,class_weight='balanced')\n",
    "dt_classifier = OneVsRestClassifier(dt)\n",
    "# fit model on train data\n",
    "dt_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=dt_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = dt_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67749529 0.67510549 0.67334765 0.67692308 0.66682386 0.65061379\n",
      " 0.65978414 0.67754137 0.68122066 0.67964353]\n",
      "\n",
      "\n",
      "f1_score: 0.67 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OneVsRestClassifier(dt)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(dt_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.3681826309828932\n",
      "Accuracy score for SGDClassifier validation: 0.33039332538736593\n",
      "\n",
      "\n",
      "f1-Score Train:  0.6385234832191268\n",
      "f1-Score validation:  0.6053076234966703\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.68      0.68      0.68      1704\n",
      "             Physics       0.85      0.46      0.60      1211\n",
      "         Mathematics       0.72      0.41      0.52      1089\n",
      "          Statistics       0.57      0.76      0.65      1069\n",
      "Quantitative Biology       0.17      0.46      0.24       116\n",
      "Quantitative Finance       0.24      0.55      0.33        44\n",
      "\n",
      "           micro avg       0.63      0.58      0.61      5233\n",
      "           macro avg       0.54      0.55      0.50      5233\n",
      "        weighted avg       0.69      0.58      0.61      5233\n",
      "         samples avg       0.51      0.59      0.53      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier( class_weight='balanced', criterion='entropy', max_depth=7, random_state=9)\n",
    "dt_classifier = OneVsRestClassifier(dt)\n",
    "# fit model on train data\n",
    "dt_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=dt_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = dt_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59883586 0.60016287 0.59055441 0.59114359 0.600085   0.57711681\n",
      " 0.59846421 0.6031746  0.58825919 0.58619824]\n",
      "\n",
      "\n",
      "f1_score: 0.59 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = OneVsRestClassifier(dt)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(dt_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  1.0\n",
      "Accuracy score for SGDClassifier validation: 0.6317044100119189\n",
      "\n",
      "\n",
      "f1-Score Train:  1.0\n",
      "f1-Score validation:  0.7929852852247531\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.78      0.89      0.83      1704\n",
      "             Physics       0.94      0.77      0.85      1211\n",
      "         Mathematics       0.92      0.70      0.79      1089\n",
      "          Statistics       0.79      0.67      0.73      1069\n",
      "Quantitative Biology       0.00      0.00      0.00       116\n",
      "Quantitative Finance       1.00      0.05      0.09        44\n",
      "\n",
      "           micro avg       0.84      0.75      0.79      5233\n",
      "           macro avg       0.74      0.51      0.55      5233\n",
      "        weighted avg       0.83      0.75      0.78      5233\n",
      "         samples avg       0.80      0.79      0.77      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=9,class_weight='balanced')\n",
    "rf_classifier = OneVsRestClassifier(rf)\n",
    "# fit model on train data\n",
    "rf_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=rf_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = rf_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77983278 0.78648853 0.79283371 0.78638083 0.79056795 0.76992936\n",
      " 0.77031093 0.78061096 0.78778703 0.77749491]\n",
      "\n",
      "\n",
      "f1_score: 0.78 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = OneVsRestClassifier(rf)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(rf_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.9992251296417715\n",
      "Accuracy score for SGDClassifier validation: 0.6193087008343265\n",
      "\n",
      "\n",
      "f1-Score Train:  0.9996908809891809\n",
      "f1-Score validation:  0.7839675291730087\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.77      0.87      0.82      1704\n",
      "             Physics       0.94      0.77      0.85      1211\n",
      "         Mathematics       0.92      0.69      0.79      1089\n",
      "          Statistics       0.78      0.67      0.72      1069\n",
      "Quantitative Biology       0.00      0.00      0.00       116\n",
      "Quantitative Finance       0.50      0.02      0.04        44\n",
      "\n",
      "           micro avg       0.84      0.74      0.78      5233\n",
      "           macro avg       0.65      0.50      0.54      5233\n",
      "        weighted avg       0.82      0.74      0.77      5233\n",
      "         samples avg       0.79      0.77      0.76      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=9,class_weight='balanced',n_jobs=-1,n_estimators=50)\n",
    "rf_classifier = OneVsRestClassifier(rf)\n",
    "# fit model on train data\n",
    "rf_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred=rf_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = rf_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.775884   0.77859126 0.78738555 0.78007663 0.78457244 0.75830586\n",
      " 0.7609904  0.76891823 0.78892558 0.76871623]\n",
      "\n",
      "\n",
      "f1_score: 0.78 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = OneVsRestClassifier(rf)\n",
    "\n",
    "fold=KFold(n_splits=10,shuffle=True,random_state=9)\n",
    "scores=cross_val_score(rf_classifier,xtrain_tfidf, ytrain,scoring='f1_micro',cv=fold,n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print('\\n')\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.6204327352923645\n",
      "Accuracy score for SGDClassifier validation: 0.6097735399284863\n",
      "\n",
      "\n",
      "f1-Score Train:  0.8170808008580622\n",
      "f1-Score validation:  0.8059674665228722\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.78      0.88      0.83      1704\n",
      "             Physics       0.90      0.84      0.87      1211\n",
      "         Mathematics       0.76      0.87      0.81      1089\n",
      "          Statistics       0.69      0.85      0.76      1069\n",
      "Quantitative Biology       0.33      0.66      0.44       116\n",
      "Quantitative Finance       0.55      0.80      0.65        44\n",
      "\n",
      "           micro avg       0.76      0.86      0.81      5233\n",
      "           macro avg       0.67      0.81      0.73      5233\n",
      "        weighted avg       0.78      0.86      0.81      5233\n",
      "         samples avg       0.80      0.88      0.82      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(class_weight='balanced',n_jobs=-1,random_state=9,C=0.07)\n",
    "lr_bag=BaggingClassifier(base_estimator=lr,random_state=9,n_jobs=-1)\n",
    "lr_bag_classifier = OneVsRestClassifier(lr_bag)\n",
    "# fit model on train data\n",
    "lr_bag_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred = lr_bag_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = lr_bag_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bossting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bossted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.8478273827263515\n",
      "Accuracy score for SGDClassifier validation: 0.6193087008343265\n",
      "\n",
      "\n",
      "f1-Score Train:  0.9302984418502418\n",
      "f1-Score validation:  0.7858150312311102\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.80      0.82      0.81      1704\n",
      "             Physics       0.93      0.77      0.84      1211\n",
      "         Mathematics       0.85      0.75      0.80      1089\n",
      "          Statistics       0.78      0.67      0.72      1069\n",
      "Quantitative Biology       0.61      0.24      0.35       116\n",
      "Quantitative Finance       0.52      0.27      0.36        44\n",
      "\n",
      "           micro avg       0.83      0.75      0.79      5233\n",
      "           macro avg       0.75      0.59      0.65      5233\n",
      "        weighted avg       0.83      0.75      0.78      5233\n",
      "         samples avg       0.79      0.78      0.77      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier(random_state=9) \n",
    "\n",
    "xgb_classifier = OneVsRestClassifier(xgb)\n",
    "# fit model on train data\n",
    "xgb_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred = xgb_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = xgb_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SGDClassifier train:  0.564284437026882\n",
      "Accuracy score for SGDClassifier validation: 0.564719904648391\n",
      "\n",
      "\n",
      "f1-Score Train:  0.7807272808050293\n",
      "f1-Score validation:  0.7787532145074044\n",
      "\n",
      "\n",
      "Classification report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Computer Science       0.75      0.85      0.80      1704\n",
      "             Physics       0.89      0.82      0.86      1211\n",
      "         Mathematics       0.76      0.85      0.80      1089\n",
      "          Statistics       0.65      0.84      0.74      1069\n",
      "Quantitative Biology       0.24      0.72      0.36       116\n",
      "Quantitative Finance       0.51      0.75      0.61        44\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      5233\n",
      "           macro avg       0.64      0.81      0.69      5233\n",
      "        weighted avg       0.75      0.84      0.79      5233\n",
      "         samples avg       0.77      0.87      0.79      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(class_weight='balanced',n_jobs=-1,random_state=9)\n",
    "lr_boost=AdaBoostClassifier(base_estimator=lr,random_state=9)\n",
    "\n",
    "lr_boost_classifier = OneVsRestClassifier(lr_boost)\n",
    "# fit model on train data\n",
    "lr_boost_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred = lr_boost_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = lr_boost_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier( class_weight='balanced', criterion='entropy', max_depth=7, random_state=9)\n",
    "dt_boost=AdaBoostClassifier(base_estimator=dt,random_state=9)\n",
    "\n",
    "dt_boost_classifier = OneVsRestClassifier(dt_boost)\n",
    "# fit model on train data\n",
    "dt_boost_classifier.fit(xtrain_tfidf, ytrain)\n",
    "\n",
    "# make predictions for validation set\n",
    "ytrain_pred = dt_boost_classifier.predict(xtrain_tfidf)\n",
    "yval_pred = dt_boost_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy score for SGDClassifier train: \",accuracy_score(ytrain, ytrain_pred))\n",
    "print(\"Accuracy score for SGDClassifier validation:\",accuracy_score(yval, yval_pred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('f1-Score Train: ',f1_score(y_true=ytrain, y_pred=ytrain_pred, average='micro'))\n",
    "print('f1-Score validation: ',f1_score(y_true=yval, y_pred=yval_pred, average='micro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(yval, yval_pred, target_names=binary_labels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
